{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010764,
     "end_time": "2020-10-20T11:22:38.247650",
     "exception": false,
     "start_time": "2020-10-20T11:22:38.236886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:38.276699Z",
     "iopub.status.busy": "2020-10-20T11:22:38.276042Z",
     "iopub.status.idle": "2020-10-20T11:22:42.913283Z",
     "shell.execute_reply": "2020-10-20T11:22:42.913885Z"
    },
    "papermill": {
     "duration": 4.655741,
     "end_time": "2020-10-20T11:22:42.914085",
     "exception": false,
     "start_time": "2020-10-20T11:22:38.258344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from torch.nn.utils import weight_norm as WN\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random as r\n",
    "r.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012843,
     "end_time": "2020-10-20T11:22:42.940518",
     "exception": false,
     "start_time": "2020-10-20T11:22:42.927675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "54de00dd-52fe-47cd-93ea-c3870d95b83f",
    "_uuid": "804fbcaa-879f-40b4-b9b9-aa0b57020b8f",
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:42.978052Z",
     "iopub.status.busy": "2020-10-20T11:22:42.977250Z",
     "iopub.status.idle": "2020-10-20T11:22:42.989822Z",
     "shell.execute_reply": "2020-10-20T11:22:42.990860Z"
    },
    "papermill": {
     "duration": 0.037267,
     "end_time": "2020-10-20T11:22:42.991047",
     "exception": false,
     "start_time": "2020-10-20T11:22:42.953780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def breaker():\n",
    "    print(\"\\n\" + 30*\"-\"+ \"\\n\")\n",
    "    \n",
    "def head(x, no_of_ele=5):\n",
    "    breaker()\n",
    "    print(x[:no_of_ele])\n",
    "    breaker()\n",
    "    \n",
    "def r2loss(y_true, y_pred):\n",
    "  y_mean = torch.mean(y_true)\n",
    "  ss_tol = 0\n",
    "  for i in range(y_true.shape[0]):\n",
    "    ss_tol += (y_true[i] - y_mean)**2\n",
    "  ss_res = torch.sum((y_true - y_pred)**2)\n",
    "  return (1 - (ss_res/ss_tol))[0]\n",
    "\n",
    "si_full = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "sc_X    = StandardScaler()\n",
    "sc_y    = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013131,
     "end_time": "2020-10-20T11:22:43.019968",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.006837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b4d8238b-ff37-47b6-ab55-fbdd72d46c34",
    "_uuid": "d6df11d9-4d40-42e2-b264-3dd4625b81c0",
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:43.056714Z",
     "iopub.status.busy": "2020-10-20T11:22:43.055945Z",
     "iopub.status.idle": "2020-10-20T11:22:43.418575Z",
     "shell.execute_reply": "2020-10-20T11:22:43.417465Z"
    },
    "papermill": {
     "duration": 0.385473,
     "end_time": "2020-10-20T11:22:43.418710",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.033237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_data_setup = pd.read_csv(\"/kaggle/input/predict-volcanic-eruptions-ingv-oe/train.csv\")\n",
    "\n",
    "y = tr_data_setup[\"time_to_eruption\"].copy()\n",
    "del tr_data_setup\n",
    "\n",
    "tr_Set = pd.read_csv('/kaggle/input/volcano-80/train_data_80.csv')\n",
    "ts_Set = pd.read_csv('/kaggle/input/volcano-80/test_data_80.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010116,
     "end_time": "2020-10-20T11:22:43.439768",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.429652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataset Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:43.468905Z",
     "iopub.status.busy": "2020-10-20T11:22:43.468184Z",
     "iopub.status.idle": "2020-10-20T11:22:43.471040Z",
     "shell.execute_reply": "2020-10-20T11:22:43.471477Z"
    },
    "papermill": {
     "duration": 0.021649,
     "end_time": "2020-10-20T11:22:43.471603",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.449954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(this, X=None, y=None, mode=\"train\"):\n",
    "        this.mode = mode\n",
    "        this.X = X\n",
    "        if mode == \"train\":\n",
    "            this.y = y\n",
    "\n",
    "    def __len__(this):\n",
    "        return this.X.shape[0]\n",
    "    \n",
    "    def __getitem__(this, idx):\n",
    "        if this.mode == \"train\":\n",
    "            return torch.FloatTensor(this.X[idx]), torch.FloatTensor(this.y[idx])\n",
    "        else:\n",
    "            return torch.FloatTensor(this.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:43.501199Z",
     "iopub.status.busy": "2020-10-20T11:22:43.500113Z",
     "iopub.status.idle": "2020-10-20T11:22:43.541436Z",
     "shell.execute_reply": "2020-10-20T11:22:43.540881Z"
    },
    "papermill": {
     "duration": 0.0597,
     "end_time": "2020-10-20T11:22:43.541541",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.481841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = tr_Set.copy().values\n",
    "X = si_full.fit_transform(X)\n",
    "X = sc_X.fit_transform(X)\n",
    "del tr_Set\n",
    "\n",
    "X_test = ts_Set.copy().values\n",
    "X_test = si_full.transform(X_test)\n",
    "X_test = sc_X.transform(X_test)\n",
    "del ts_Set\n",
    "\n",
    "y = y.values\n",
    "y = si_full.fit_transform(y.reshape(-1,1)).reshape(-1)\n",
    "y = sc_y.fit_transform(y.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "num_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011307,
     "end_time": "2020-10-20T11:22:43.564006",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.552699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ANN Setup and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010376,
     "end_time": "2020-10-20T11:22:43.585489",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.575113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:43.984229Z",
     "iopub.status.busy": "2020-10-20T11:22:43.981382Z",
     "iopub.status.idle": "2020-10-20T11:22:44.008575Z",
     "shell.execute_reply": "2020-10-20T11:22:44.007871Z"
    },
    "papermill": {
     "duration": 0.412592,
     "end_time": "2020-10-20T11:22:44.008690",
     "exception": false,
     "start_time": "2020-10-20T11:22:43.596098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\n",
      "Device     : cuda:0\n",
      "Batch Size : 256\n",
      "Epochs     : 50\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ANN_CFG():\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    IL = num_features\n",
    "    HL = [64, 128, 32]\n",
    "    OL = 1\n",
    "    \n",
    "    batch_size = 256\n",
    "    \n",
    "    \n",
    "class ANN(nn.Module):\n",
    "    def __init__(this, IL=None, HL=None, OL=None):\n",
    "        super(ANN, this).__init__()\n",
    "        \n",
    "        this.BN1 = nn.BatchNorm1d(IL)\n",
    "        this.DP1 = nn.Dropout(p=0.25)\n",
    "        this.FC1 = WN(nn.Linear(IL, HL[0]))\n",
    "        \n",
    "        this.BN2 = nn.BatchNorm1d(HL[0])\n",
    "        this.DP2 = nn.Dropout(p=0.5)\n",
    "        this.FC2 = WN(nn.Linear(HL[0], HL[1]))\n",
    "        \n",
    "        this.BN3 = nn.BatchNorm1d(HL[1])\n",
    "        this.DP3 = nn.Dropout(p=0.5)\n",
    "        this.FC3 = WN(nn.Linear(HL[1], HL[2]))\n",
    "        \n",
    "        this.BN4 = nn.BatchNorm1d(HL[2])\n",
    "        this.DP4 = nn.Dropout(p=0.5)\n",
    "        this.FC4 = WN(nn.Linear(HL[2], OL))\n",
    "        \n",
    "    def getOptimizer(this, idx, Adam=True, SGD=False):\n",
    "        if Adam:\n",
    "            \n",
    "            opts = [optim.Adam(this.parameters(), lr=1e-2),\n",
    "                    optim.Adam(this.parameters(), lr=1e-2, weight_decay=1e-5),\n",
    "                    \n",
    "                    optim.Adam(this.parameters(), lr=5e-3),\n",
    "                    optim.Adam(this.parameters(), lr=5e-3, weight_decay=1e-5),\n",
    "                    \n",
    "                    optim.Adam(this.parameters(), lr=1e-3),\n",
    "                    optim.Adam(this.parameters(), lr=1e-3, weight_decay=1e-5)]\n",
    "            return opts[idx]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            opts = [optim.SGD(this.parameters(), lr=1e-2), \n",
    "                    optim.SGD(this.parameters(), lr=1e-2, momentum=0.9),\n",
    "                    optim.SGD(this.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-5),\n",
    "                    \n",
    "                    optim.SGD(this.parameters(), lr=1e-3), \n",
    "                    optim.SGD(this.parameters(), lr=1e-3, momentum=0.9),\n",
    "                    optim.SGD(this.parameters(), lr=1e-3, momentum=0.9, weight_decay=1e-5),\n",
    "                    \n",
    "                    optim.SGD(this.parameters(), lr=1e-4), \n",
    "                    optim.SGD(this.parameters(), lr=1e-4, momentum=0.9),\n",
    "                    optim.SGD(this.parameters(), lr=1e-4, momentum=0.9, weight_decay=1e-5),]       \n",
    "            return opts[idx]\n",
    "\n",
    "    def forward(this, x):\n",
    "        x = this.BN1(x)\n",
    "        x = this.DP1(x)\n",
    "        x = F.relu(this.FC1(x))\n",
    "        \n",
    "        x = this.BN2(x)\n",
    "        x = this.DP2(x)\n",
    "        x = F.relu(this.FC2(x))\n",
    "        \n",
    "        x = this.BN3(x)\n",
    "        x = this.DP3(x)\n",
    "        x = F.relu(this.FC3(x))\n",
    "        \n",
    "        x = this.BN4(x)\n",
    "        x = this.DP4(x)\n",
    "        x = this.FC4(x)\n",
    "        return x\n",
    "    \n",
    "cfg = ANN_CFG()\n",
    "\n",
    "\n",
    "breaker()\n",
    "print(\"Device     :\", cfg.device)\n",
    "print(\"Batch Size :\", repr(cfg.batch_size))\n",
    "print(\"Epochs     :\", repr(cfg.epochs))\n",
    "breaker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015891,
     "end_time": "2020-10-20T11:22:44.041071",
     "exception": false,
     "start_time": "2020-10-20T11:22:44.025180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T11:22:44.098284Z",
     "iopub.status.busy": "2020-10-20T11:22:44.097457Z",
     "iopub.status.idle": "2020-10-20T11:43:34.134623Z",
     "shell.execute_reply": "2020-10-20T11:43:34.129353Z"
    },
    "papermill": {
     "duration": 1250.077138,
     "end_time": "2020-10-20T11:43:34.134764",
     "exception": false,
     "start_time": "2020-10-20T11:22:44.057626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 49\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 97\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 53\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 5\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 33\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 65\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 62\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 51\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 38\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Seed 61\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Time Taken to Train : 20.83 minutes\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestLoss = {\"train\": np.inf, \"valid\": np.inf}\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "LP = []\n",
    "name_getter = []\n",
    "\n",
    "seeders = [r.randint(0,99) for i in range(10)]\n",
    "#seeders = [0]\n",
    "\n",
    "start_time = time()\n",
    "for seed in range(len(seeders)):\n",
    "    breaker()\n",
    "    print(\"Seed {seed}\".format(seed=seeders[seed]))\n",
    "    fold = 0\n",
    "    \n",
    "    for tr_idx, ts_idx in KFold(n_splits=n_folds, shuffle=True, random_state=seeders[seed]).split(X, y):\n",
    "        X_train, X_valid = X[tr_idx], X[ts_idx]\n",
    "        y_train, y_valid = y[tr_idx], y[ts_idx]\n",
    "        \n",
    "        name = \"Seed_{seed}_Fold_{fold}\".format(seed=seeders[seed], fold=fold)\n",
    "        \n",
    "        Net = ANN(cfg.IL, cfg.HL, cfg.OL)\n",
    "        Net = Net.to(cfg.device)\n",
    "        Net.train()\n",
    "        \n",
    "        optim_idx = 3\n",
    "        optimizer = Net.getOptimizer(Adam=False, SGD=True, idx=optim_idx)\n",
    "        \n",
    "        tr_data_setup = DS(X_train, y_train.reshape(-1,1))\n",
    "        va_data_setup = DS(X_valid, y_valid.reshape(-1,1))  \n",
    "\n",
    "        dataloaders = { \"train\": DL(tr_data_setup, batch_size=cfg.batch_size, shuffle=True, num_workers=4,), #generator=seeds[seed]),\n",
    "                        \"valid\" : DL(va_data_setup, batch_size=cfg.batch_size, shuffle=False, num_workers=4)}\n",
    "\n",
    "        for e in range(cfg.epochs):\n",
    "            epochLoss = {\"train\": 0, \"valid\": 0}\n",
    "            for phase in [\"train\", \"valid\"]:\n",
    "                if phase == \"train\":\n",
    "                  Net.train()\n",
    "                else:\n",
    "                  Net.eval()\n",
    "                lossPerPass = 0\n",
    "                \n",
    "                for tensor_x, tensor_y in dataloaders[phase]:\n",
    "                    tensor_x, tensor_y = tensor_x.to(cfg.device), tensor_y.to(cfg.device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        output = Net(tensor_x)\n",
    "                        loss_1 = nn.MSELoss()(output, tensor_y)\n",
    "                        loss_2 = nn.L1Loss()(output, tensor_y)\n",
    "                        loss = loss_1 + loss_2\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    lossPerPass += loss.item() / len(dataloaders[phase])\n",
    "                epochLoss[phase] = lossPerPass\n",
    "            LP.append(epochLoss)\n",
    "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
    "                bestLoss = epochLoss\n",
    "                torch.save(Net.state_dict(), name)\n",
    "                name_getter.append(name)\n",
    "        fold += 1        \n",
    "                \n",
    "\n",
    "breaker()\n",
    "print(\"Time Taken to Train : %.2f minutes\" % ((time() - start_time)/60))\n",
    "breaker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031891,
     "end_time": "2020-10-20T11:43:34.199119",
     "exception": false,
     "start_time": "2020-10-20T11:43:34.167228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T11:43:34.276979Z",
     "iopub.status.busy": "2020-10-20T11:43:34.276252Z",
     "iopub.status.idle": "2020-10-20T11:43:40.074403Z",
     "shell.execute_reply": "2020-10-20T11:43:40.073491Z"
    },
    "papermill": {
     "duration": 5.842961,
     "end_time": "2020-10-20T11:43:40.074576",
     "exception": false,
     "start_time": "2020-10-20T11:43:34.231615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\n",
      "   segment_id  time_to_eruption\n",
      "0  1000213997        24137492.0\n",
      "1   100023368        24695074.0\n",
      "2  1000488999        22801100.0\n",
      "3  1001028887        23311502.0\n",
      "4  1001857862        22054174.0\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ts_data_setup = DS(X_test, None, mode=\"test\")\n",
    "ts_data = DL(ts_data_setup, batch_size=cfg.batch_size, shuffle=False) #,num_workers=4)\n",
    "\n",
    "y_pred = np.zeros((X_test.shape[0], 1))\n",
    "\n",
    "for name in name_getter:\n",
    "    Pred = torch.zeros(cfg.batch_size, 1).to(cfg.device)\n",
    "    Net.load_state_dict(torch.load(name))\n",
    "    Net.eval()\n",
    "    for feat in ts_data:\n",
    "        feat = feat.to(cfg.device)\n",
    "        with torch.no_grad():\n",
    "            output = Net(feat)\n",
    "        Pred = torch.cat((Pred, output), dim=0)\n",
    "\n",
    "    Pred = Pred[cfg.batch_size:]\n",
    "    Pred = Pred.cpu().numpy()\n",
    "    Pred = sc_y.inverse_transform(Pred)\n",
    "    y_pred = np.add(y_pred, Pred)\n",
    "    \n",
    "y_pred = np.divide(y_pred, len(name_getter))\n",
    "\n",
    "ss = pd.read_csv(\"/kaggle/input/predict-volcanic-eruptions-ingv-oe/sample_submission.csv\")\n",
    "ss[\"time_to_eruption\"] = Pred\n",
    "ss.to_csv(\"./submission.csv\", index=False)\n",
    "\n",
    "breaker()\n",
    "print(ss.head(5))\n",
    "breaker()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1267.487927,
   "end_time": "2020-10-20T11:43:41.438764",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-20T11:22:33.950837",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
