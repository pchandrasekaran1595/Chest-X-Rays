{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012803,
     "end_time": "2020-11-07T15:10:19.004482",
     "exception": false,
     "start_time": "2020-11-07T15:10:18.991679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:19.031892Z",
     "iopub.status.busy": "2020-11-07T15:10:19.031241Z",
     "iopub.status.idle": "2020-11-07T15:10:21.322909Z",
     "shell.execute_reply": "2020-11-07T15:10:21.322161Z"
    },
    "papermill": {
     "duration": 2.308484,
     "end_time": "2020-11-07T15:10:21.323030",
     "exception": false,
     "start_time": "2020-11-07T15:10:19.014546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader as DL\n",
    "from torch.nn.utils import weight_norm as WN\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from time import time\n",
    "import random as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0096,
     "end_time": "2020-11-07T15:10:21.343482",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.333882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.384749Z",
     "iopub.status.busy": "2020-11-07T15:10:21.383903Z",
     "iopub.status.idle": "2020-11-07T15:10:21.386697Z",
     "shell.execute_reply": "2020-11-07T15:10:21.386104Z"
    },
    "papermill": {
     "duration": 0.033391,
     "end_time": "2020-11-07T15:10:21.386831",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.353440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def breaker():\n",
    "    print(\"\\n\" + 30*\"-\" +\"\\n\")\n",
    "    \n",
    "def head(x=None, no_of_ele=5):\n",
    "    breaker()\n",
    "    print(x[:no_of_ele])\n",
    "    breaker()\n",
    "    \n",
    "def getCol(x):\n",
    "    return [col for col in x.columns]\n",
    "\n",
    "def getObj(x):\n",
    "    s = (x.dtypes == \"object\")\n",
    "    return list(s[s].index)\n",
    "\n",
    "def preprocess(x=None, *args):\n",
    "    df = x.copy()\n",
    "    df[args[0]]  = df[args[0]].map({'Female' : 0, 'Male' : 1})\n",
    "    df[args[1]]  = df[args[1]].map({'No' : 0, 'Yes' : 1})\n",
    "    df[args[2]]  = df[args[2]].map({'No' : 0, 'Yes' : 1})\n",
    "    df[args[3]]  = df[args[3]].map({'No' : 0, 'Yes' : 1})\n",
    "    df[args[4]]  = df[args[4]].map({'No' : 0, 'No phone service' : 1, 'Yes' : 2})\n",
    "    df[args[5]]  = df[args[5]].map({'DSL' : 0, 'Fiber optic' : 1, 'No' : 2})\n",
    "    df[args[6]]  = df[args[6]].map({'No' : 0, 'No internet service' : 1, 'Yes' : 2})\n",
    "    df[args[7]]  = df[args[7]].map({'No' : 0, 'No internet service' : 1, 'Yes' : 2})\n",
    "    df[args[8]]  = df[args[8]].map({'No' : 0, 'No internet service' : 1, 'Yes' : 2})\n",
    "    df[args[9]]  = df[args[9]].map({'No' : 0, 'No internet service' : 1, 'Yes' : 2})\n",
    "    df[args[10]] = df[args[10]].map({'No' : 0, 'No internet service' : 1, 'Yes' : 2})\n",
    "    df[args[11]] = df[args[11]].map({'No' : 0, 'No internet service' : 1, 'Yes' : 2})\n",
    "    df[args[12]] = df[args[12]].map({'Month-to-month' : 0, 'One year' : 1, 'Two year' : 2})\n",
    "    df[args[13]] = df[args[13]].map({'No' : 0, 'Yes' : 1})\n",
    "    df[args[14]] = df[args[14]].map({'Bank transfer (automatic)' : 0,\n",
    "                                     'Credit card (automatic)' : 1,\n",
    "                                     'Electronic check' : 2,\n",
    "                                     'Mailed check' : 3})\n",
    "    return df\n",
    "    \n",
    "si_mean = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "si_mf   = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "sc_X    = StandardScaler()\n",
    "mms_X   = MinMaxScaler(feature_range=(0, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009406,
     "end_time": "2020-11-07T15:10:21.406018",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.396612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.437964Z",
     "iopub.status.busy": "2020-11-07T15:10:21.437300Z",
     "iopub.status.idle": "2020-11-07T15:10:21.575435Z",
     "shell.execute_reply": "2020-11-07T15:10:21.575924Z"
    },
    "papermill": {
     "duration": 0.160509,
     "end_time": "2020-11-07T15:10:21.576081",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.415572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\n",
      "Train Set Shape : (5634, 21)\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Test Set Shape : (1409, 20)\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_Set = pd.read_csv(\"../input/labdata-churn-challenge-2020/train.csv\")\n",
    "ts_Set = pd.read_csv(\"../input/labdata-churn-challenge-2020/test.csv\")\n",
    "\n",
    "breaker()\n",
    "print(\"Train Set Shape :\", repr(tr_Set.shape))\n",
    "breaker()\n",
    "print(\"Test Set Shape :\", repr(ts_Set.shape))\n",
    "breaker()\n",
    "#print(\"Train Set Columns\\n\")\n",
    "#for name in getCol(tr_Set):\n",
    "#    print(name)\n",
    "#breaker()\n",
    "#print(\"Test Set Columns\\n\")\n",
    "#for name in getCol(ts_Set):\n",
    "#    print(name)\n",
    "#breaker()\n",
    "tr_Proc = preprocess(tr_Set, 'gender', 'Partner', 'Dependents', 'PhoneService',\n",
    "                     'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "                     'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "                     'StreamingTV', 'StreamingMovies', 'Contract', \n",
    "                     'PaperlessBilling', 'PaymentMethod')\n",
    "\n",
    "ts_Proc = preprocess(ts_Set, 'gender', 'Partner', 'Dependents', 'PhoneService',\n",
    "                     'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
    "                     'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "                     'StreamingTV', 'StreamingMovies', 'Contract', \n",
    "                     'PaperlessBilling', 'PaymentMethod')\n",
    "\n",
    "tr_Proc[\"TotalCharges\"] = pd.to_numeric(tr_Proc[\"TotalCharges\"], errors=\"coerce\")\n",
    "ts_Proc[\"TotalCharges\"] = pd.to_numeric(ts_Proc[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "X = tr_Proc.iloc[:, 1:-1].copy().values\n",
    "y = tr_Proc.iloc[:, -1].copy().values\n",
    "\n",
    "X_test = ts_Proc.iloc[:, 1:].copy().values\n",
    "\n",
    "X, X_test, y = X.astype(float), X_test.astype(float), y.astype(float)\n",
    "\n",
    "X = si_mf.fit_transform(X)\n",
    "X_test = si_mf.transform(X_test)\n",
    "\n",
    "########## Scaling ##########\n",
    "X = sc_X.fit_transform(X)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "#X = mms_X.fit_transform(X)\n",
    "#X_test = mms_X.transform(X_test)\n",
    "\n",
    "num_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01494,
     "end_time": "2020-11-07T15:10:21.602423",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.587483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataset Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.632516Z",
     "iopub.status.busy": "2020-11-07T15:10:21.631904Z",
     "iopub.status.idle": "2020-11-07T15:10:21.634814Z",
     "shell.execute_reply": "2020-11-07T15:10:21.635268Z"
    },
    "papermill": {
     "duration": 0.02098,
     "end_time": "2020-11-07T15:10:21.635412",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.614432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(this, X=None, y=None, mode=\"train\"):\n",
    "        this.mode = mode\n",
    "        this.X = X\n",
    "        if mode == \"train\":\n",
    "            this.y = y\n",
    "            \n",
    "    def __len__(this):\n",
    "        return this.X.shape[0]\n",
    "    \n",
    "    def __getitem__(this, idx):\n",
    "        if this.mode == \"train\":\n",
    "            return torch.FloatTensor(this.X[idx]) , torch.FloatTensor(this.y[idx])\n",
    "        else:\n",
    "            return torch.FloatTensor(this.X[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010188,
     "end_time": "2020-11-07T15:10:21.656088",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.645900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010058,
     "end_time": "2020-11-07T15:10:21.676534",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.666476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.705515Z",
     "iopub.status.busy": "2020-11-07T15:10:21.704884Z",
     "iopub.status.idle": "2020-11-07T15:10:21.708105Z",
     "shell.execute_reply": "2020-11-07T15:10:21.707466Z"
    },
    "papermill": {
     "duration": 0.021029,
     "end_time": "2020-11-07T15:10:21.708216",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.687187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG():\n",
    "    tr_batch_size = 512\n",
    "    va_batch_size = 512\n",
    "    ts_batch_size = 512\n",
    "    \n",
    "    epochs  = 50\n",
    "    n_folds = 4\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    IL = num_features\n",
    "    OL = 1\n",
    "    HL_1 = [64]\n",
    "    HL_2 = [128, 64]\n",
    "    \n",
    "cfg = CFG()\n",
    "    \n",
    "ts_data_setup = DS(X_test, None, \"test\")\n",
    "ts_data = DL(ts_data_setup, batch_size=cfg.ts_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010364,
     "end_time": "2020-11-07T15:10:21.729438",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.719074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.766625Z",
     "iopub.status.busy": "2020-11-07T15:10:21.763817Z",
     "iopub.status.idle": "2020-11-07T15:10:21.769670Z",
     "shell.execute_reply": "2020-11-07T15:10:21.769186Z"
    },
    "papermill": {
     "duration": 0.029796,
     "end_time": "2020-11-07T15:10:21.769817",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.740021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(this, IL=None, HL=None, OL=None):\n",
    "        super(MLP, this).__init__()\n",
    "        \n",
    "        this.DP1 = nn.Dropout(p=0.2)\n",
    "        this.DP2 = nn.Dropout(p=0.5)\n",
    "        this.HL  = HL\n",
    "        \n",
    "        if len(HL) == 1:\n",
    "            this.BN1 = nn.BatchNorm1d(IL)\n",
    "            this.FC1 = WN(nn.Linear(IL, HL[0]))\n",
    "\n",
    "            this.BN2 = nn.BatchNorm1d(HL[0])\n",
    "            this.FC2 = WN(nn.Linear(HL[0], OL))\n",
    "            \n",
    "        elif len(HL) == 2:\n",
    "            this.BN1 = nn.BatchNorm1d(IL)\n",
    "            this.FC1 = WN(nn.Linear(IL, HL[0]))\n",
    "\n",
    "            this.BN2 = nn.BatchNorm1d(HL[0])\n",
    "            this.FC2 = WN(nn.Linear(HL[0], HL[1]))\n",
    "            \n",
    "            this.BN3 = nn.BatchNorm1d(HL[1])\n",
    "            this.FC3 = WN(nn.Linear(HL[1], OL))\n",
    "            \n",
    "        else:\n",
    "            raise NotImplementedError(\"Only Supports Networks of Depth 1 and 2\")\n",
    "        \n",
    "    def getOptimizer(this, lr=1e-3, wd=0):\n",
    "        return optim.Adam(this.parameters(), lr=lr, weight_decay=wd)\n",
    "    \n",
    "    def forward(this, x):\n",
    "        if len(this.HL) == 1:\n",
    "            x = this.BN1(x)\n",
    "            x = this.DP1(x)\n",
    "            x = F.relu(this.FC1(x))\n",
    "            x = this.BN2(x)\n",
    "            x = this.DP2(x)\n",
    "            x = torch.sigmoid(this.FC2(x))\n",
    "            return x\n",
    "        else:\n",
    "            x = this.BN1(x)\n",
    "            x = this.DP1(x)\n",
    "            x = F.relu(this.FC1(x))\n",
    "            x = this.BN2(x)\n",
    "            x = this.DP2(x)\n",
    "            x = F.relu(this.FC2(x))\n",
    "            x = this.BN3(x)\n",
    "            x = this.DP2(x)\n",
    "            x = torch.sigmoid(this.FC3(x))\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010278,
     "end_time": "2020-11-07T15:10:21.790814",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.780536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**ANN Helpers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.826172Z",
     "iopub.status.busy": "2020-11-07T15:10:21.820929Z",
     "iopub.status.idle": "2020-11-07T15:10:21.840962Z",
     "shell.execute_reply": "2020-11-07T15:10:21.840458Z"
    },
    "papermill": {
     "duration": 0.038929,
     "end_time": "2020-11-07T15:10:21.841084",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.802155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(X=None, y=None, n_folds=None, HL_Used=None):\n",
    "    breaker()\n",
    "    print(\"Training ...\")\n",
    "    breaker()\n",
    "    \n",
    "    LP = []\n",
    "    names = []\n",
    "    bestLoss = {\"train\" : np.inf, \"valid\" : np.inf}\n",
    "    fold = 0\n",
    "    \n",
    "    start_time = time()\n",
    "    for tr_idx, va_idx in KFold(n_splits=n_folds, shuffle=True, random_state=0).split(X, y):\n",
    "        print(\"Processing Fold {fold} ...\".format(fold=fold+1))\n",
    "        \n",
    "        X_train, X_valid, y_train, y_valid = X[tr_idx], X[va_idx], y[tr_idx], y[va_idx]\n",
    "        \n",
    "        tr_data_setup = DS(X_train, y_train.reshape(-1,1))\n",
    "        va_data_setup = DS(X_valid, y_valid.reshape(-1,1))\n",
    "        \n",
    "        DLS = {\"train\" : DL(tr_data_setup, batch_size=cfg.tr_batch_size, shuffle=True, generator=torch.manual_seed(0)), #, drop_last=True),\n",
    "               \"valid\" : DL(va_data_setup, batch_size=cfg.va_batch_size, shuffle=False) #drop_last=True)\n",
    "              }\n",
    "        \n",
    "        torch.manual_seed(0)\n",
    "        model = MLP(cfg.IL, HL_Used, cfg.OL)\n",
    "        model.to(cfg.device)\n",
    "        \n",
    "        optimizer = model.getOptimizer()\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, eps=1e-6, verbose=True)\n",
    "        \n",
    "        for e in range(cfg.epochs):\n",
    "            epochLoss = {\"train\" : 0, \"valid\" : 0}\n",
    "            for phase in [\"train\", \"valid\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "                lossPerPass = 0\n",
    "                \n",
    "                for f, l in DLS[phase]:\n",
    "                    f, l = f.to(cfg.device), l.to(cfg.device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        output = model(f)\n",
    "                        loss   = nn.BCELoss()(output, l)\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                    lossPerPass += (loss.item() / l.shape[0])\n",
    "                epochLoss[phase] = lossPerPass\n",
    "            LP.append(epochLoss)\n",
    "            scheduler.step(epochLoss[\"valid\"])\n",
    "            #name = \"./Model_Fold_{fold}\".format(fold=fold)\n",
    "            #names.append(name)\n",
    "            #torch.save(model.state_dict(), name)\n",
    "            if epochLoss[\"valid\"] < bestLoss[\"valid\"]:\n",
    "                bestLoss = epochLoss\n",
    "                name = \"./Model_Fold_{fold}\".format(fold=fold)\n",
    "                names.append(name)\n",
    "                torch.save(model.state_dict(), name)\n",
    "        fold += 1\n",
    "        \n",
    "    breaker()\n",
    "    print(\"Time Taken to Train {fold} folds for {e} epochs : {:.2f} minutes\".format((time()-start_time)/60, fold=n_folds, e=cfg.epochs))\n",
    "    breaker()\n",
    "    print(\"Best Loss :\", repr(bestLoss))\n",
    "    breaker()\n",
    "    print(\"Training Complete\")\n",
    "    breaker()\n",
    "    return LP, names, model\n",
    "    \n",
    "def eval_fn(model=None, names=None, dataloader=None, num_obs_test=None):\n",
    "    y_pred = np.zeros((num_obs_test, 1))\n",
    "    \n",
    "    for name in names:\n",
    "        Pred = torch.zeros(cfg.ts_batch_size, 1).to(cfg.device)\n",
    "        \n",
    "        model.load_state_dict(torch.load(name))\n",
    "        model.eval()\n",
    "        \n",
    "        for X in dataloader:\n",
    "            X = X.to(cfg.device)\n",
    "            with torch.no_grad():\n",
    "                Prob = model(X)\n",
    "            Pred = torch.cat((Pred, Prob), dim=0)\n",
    "        Pred = Pred[cfg.ts_batch_size:].cpu().numpy()\n",
    "        y_pred = np.add(y_pred, Pred)\n",
    "    y_pred = np.divide(y_pred, len(names))\n",
    "    \n",
    "    y_pred[np.argwhere(y_pred > 0.5)]  = 1\n",
    "    y_pred[np.argwhere(y_pred <= 0.5)] = 0\n",
    "    return y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010493,
     "end_time": "2020-11-07T15:10:21.862508",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.852015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:21.889808Z",
     "iopub.status.busy": "2020-11-07T15:10:21.888873Z",
     "iopub.status.idle": "2020-11-07T15:10:57.720573Z",
     "shell.execute_reply": "2020-11-07T15:10:57.721382Z"
    },
    "papermill": {
     "duration": 35.848336,
     "end_time": "2020-11-07T15:10:57.721596",
     "exception": false,
     "start_time": "2020-11-07T15:10:21.873260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------\n",
      "\n",
      "Training ...\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Processing Fold 1 ...\n",
      "Processing Fold 2 ...\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Processing Fold 3 ...\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Processing Fold 4 ...\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Time Taken to Train 4 folds for 50 epochs : 0.60 minutes\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Best Loss : {'train': 0.010628409043871329, 'valid': 0.002645076979435497}\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Training Complete\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LP, Names, Network = train_fn(X=X, y=y, n_folds=cfg.n_folds, HL_Used=cfg.HL_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013043,
     "end_time": "2020-11-07T15:10:57.748750",
     "exception": false,
     "start_time": "2020-11-07T15:10:57.735707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:10:57.783382Z",
     "iopub.status.busy": "2020-11-07T15:10:57.782456Z",
     "iopub.status.idle": "2020-11-07T15:10:58.086697Z",
     "shell.execute_reply": "2020-11-07T15:10:58.086123Z"
    },
    "papermill": {
     "duration": 0.324975,
     "end_time": "2020-11-07T15:10:58.086861",
     "exception": false,
     "start_time": "2020-11-07T15:10:57.761886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = pd.read_csv(\"../input/labdata-churn-challenge-2020/sample_submission.csv\")\n",
    "\n",
    "y_pred = eval_fn(Network, set(Names), ts_data, ts_data_setup.__len__())\n",
    "\n",
    "ss[\"Churn\"] = y_pred\n",
    "ss.to_csv(\"./submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 43.662918,
   "end_time": "2020-11-07T15:10:58.208566",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-07T15:10:14.545648",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
